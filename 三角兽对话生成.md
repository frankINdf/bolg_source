## GAN 对话生成 ##

eural Response Generation via GAN with an Approximate Embedding Layer

__基于检索__ 偏向工程实践

__基于End_to_End__ 看作翻译过程

### 解决的问题 ###

safe response偏向于使用"我也觉得"这种回复

### 之前的解决方案 ###


attention mechanism强化语义信息，削弱decoder中语言模型的影响

[4] Lifeng Shang, Zhengdong Lu, and Hang Li. 2015. Neural responding machine for short-text conversation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1577–1586, Beijing, China. Association for Computational Linguistics.


使用外部知识或者user modeling

[9] Jiwei Li, Michel Galley, Chris Brockett, Georgios P. Spithourakis, Jianfeng Gao, and William B. Dolan. 2016b. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany.

[10] Xing Chen, Wu Wei, Wu Yu, Liu Jie, Huang Yalou, Zhou Ming, and Ma Wei-Ying. 2017. Topic aware neural response generation. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9, 2017, San Francisco, California, USA., pages 3351–3357.

## 根本原因 ##

陷入了局部最优解

## 解决方案 ##

过程：使用encoder和decoder进行生成，同时构建一个判别器

问题：无论最大概率贪心算法还是使用beam searching, 都会出现无法反向传播

解决：构建一个Approximate Embedding Layer, 不去直接得到具体的词，而是得到

一个采样向量, GRU输出的结果加上扰动向量$z_i$后, 经过全连接层和softmax之后

得到整个词表中每个词语的概率分布，将改概率作为权重，对embedding进行加权求和

得到当前采样的词语的近似向量表示，作为下一个generation step的输入

该近似向量同样可以用来拼接组成fake response


411600411600411600411600
411600
411600411600
